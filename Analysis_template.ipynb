{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "document = Document()\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "# import matplotlib.gridspec as gridspec\n",
    "from matplotlib import cm\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import gc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spk_times():\n",
    "    cell_type = ['et', 'apimi', 'mi', 'gr'] \n",
    "    binL = 25\n",
    "    nrows = 1\n",
    "    ncols = 3\n",
    "    os.chdir(add)\n",
    "    for cidx, ctype in enumerate(cell_type):\n",
    "        if ctype in ['apimi', 'mi']:\n",
    "            data = [[[] for _ in range(param[\"mi_dup\"])] for _ in range(6)]\n",
    "            avg_data = np.zeros((int(param['num_mi']/param[\"mi_dup\"]), nclasses, param[\"mi_dup\"]))\n",
    "            cnt = [[[] for _ in range(param[\"mi_dup\"])] for _ in range(6)]\n",
    "        elif ctype in ['gr']:\n",
    "            data = [[] for _ in range(nclasses)]\n",
    "            cnt = [[] for _ in range(nclasses)]\n",
    "            # f_cnt = [[[] for _ in range(nclasses)] for _ in range(6)]\n",
    "            list_cnt = [[[] for _ in range(nclasses)] for _ in range(6)]\n",
    "        '''\n",
    "        elif ctype in ['etach']:\n",
    "            v_etach_train = [[] for _ in range(nclasses)]\n",
    "            v_etach_val = [[] for _ in range(nclasses)]\n",
    "            v_etach_test = [[] for _ in range(nclasses)]\n",
    "        '''\n",
    "        if ctype in ['et']:\n",
    "            cnt_train = [[] for _ in range(nclasses)]\n",
    "            cnt_val = [[] for _ in range(nclasses)]\n",
    "            cnt_test = [[] for _ in range(nclasses)]\n",
    "            \n",
    "        for gidx in range(len(group_type)):\n",
    "            for st in range(len(stat)):\n",
    "                if st == 0:\n",
    "                    y = y_train[gidx]\n",
    "                elif st == 1:\n",
    "                    y = y_val[gidx]\n",
    "                elif st == 2:\n",
    "                    y = y_test[gidx]  \n",
    "                for s_idx in range(len(y)):\n",
    "                    if st == 0:\n",
    "                        if ctype in ['apimi', 'mi', 'gr']:\n",
    "                            t_ctype = pd.read_csv('spk_time_' + ctype + stat[st] + str(gidx) + \n",
    "                                                  str(s_idx) + '.csv', header=None)\n",
    "                            t_ctype = np.asarray(t_ctype.values.flatten())\n",
    "                            if ctype in ['apimi', 'mi']:\n",
    "                                for i in range(param['mi_dup']):\n",
    "                                    num_mi = param['num_mi']/param[\"mi_dup\"]\n",
    "                                    data[y[s_idx]-1][i].append(t_ctype[int(i*num_mi): int((i*num_mi) + num_mi)])\n",
    "                                    avg_data[:, y[s_idx]-1, i] = (avg_data[:, y[s_idx]-1, i] + \n",
    "                                                                  t_ctype[int(i*num_mi): int((i*num_mi) + num_mi)])\n",
    "                            elif ctype in ['gr']:\n",
    "                                data[y[s_idx]-1].append(t_ctype)\n",
    "\n",
    "                            t_ctype = pd.read_csv('count_' + ctype + stat[st] + str(gidx) + \n",
    "                                                  str(s_idx) + '.csv', header=None)\n",
    "                            t_ctype = np.asarray(t_ctype.values.flatten())\n",
    "                            if ctype in ['apimi', 'mi']:\n",
    "                                for i in range(param['mi_dup']):\n",
    "                                    num_mi = param['num_mi']/param[\"mi_dup\"]\n",
    "                                    cnt[y[s_idx]-1][i].append(np.sum(\n",
    "                                        t_ctype[int(i*num_mi): int((i*num_mi) + num_mi)]))\n",
    "                            elif ctype in ['gr']:\n",
    "                                cnt[y[s_idx]-1].append(np.sum(t_ctype))\n",
    "                                for gr_idx in range(nclasses):\n",
    "                                    '''\n",
    "                                    f_cnt[y[s_idx]-1][gr_idx].append(\n",
    "                                        np.sum(t_ctype[param[\"gr_orth_idx\"][gr_idx+1]]))\n",
    "                                    '''\n",
    "                                    list_cnt[y[s_idx]-1][gr_idx].append(\n",
    "                                        np.sum(t_ctype[param[\"idx_list_all\"][gr_idx]]))\n",
    "                                \n",
    "                        if ctype in ['et']:\n",
    "                            t_ctype = pd.read_csv('count_' + ctype + stat[st] + str(gidx) + \n",
    "                                                  str(s_idx) + '.csv', header=None)\n",
    "                            t_ctype = np.asarray(t_ctype.values.flatten())\n",
    "                            if st == 0:\n",
    "                                cnt_train[y[s_idx]-1].append(t_ctype)    \n",
    "                            elif st == 1:\n",
    "                                cnt_val[y[s_idx]-1].append(t_ctype)\n",
    "                            elif st == 2:\n",
    "                                cnt_test[y[s_idx]-1].append(t_ctype)\n",
    "                                        \n",
    "                    else:\n",
    "                        if gidx == 5:\n",
    "                            if ctype in ['apimi', 'mi', 'gr']:\n",
    "                                t_ctype = pd.read_csv('spk_time_' + ctype + stat[st] + \n",
    "                                                      AL[st-1] + str(gidx) + \n",
    "                                                      str(s_idx) + '.csv', header=None)\n",
    "                                t_ctype = np.asarray(t_ctype.values.flatten())\n",
    "                                if ctype in ['apimi', 'mi']:\n",
    "                                    for i in range(param['mi_dup']):\n",
    "                                        num_mi = param['num_mi']/param[\"mi_dup\"]\n",
    "                                        data[y[s_idx]-1][i].append(\n",
    "                                            t_ctype[int(i*num_mi): int((i*num_mi) + num_mi)])\n",
    "                                        avg_data[:, y[s_idx]-1, i] = (avg_data[:, y[s_idx]-1, i] + \n",
    "                                                                  t_ctype[int(i*num_mi): int((i*num_mi) \n",
    "                                                                                             + num_mi)])\n",
    "                                else:\n",
    "                                    data[y[s_idx]-1].append(t_ctype)\n",
    "\n",
    "                                t_ctype = pd.read_csv('count_' + ctype + stat[st] + AL[st-1] + str(gidx) + \n",
    "                                                      str(s_idx) + '.csv', header=None)\n",
    "                                t_ctype = np.asarray(t_ctype.values.flatten())\n",
    "                                if ctype in ['apimi', 'mi']:\n",
    "                                    for i in range(param['mi_dup']):\n",
    "                                        num_mi = param['num_mi']/param[\"mi_dup\"]\n",
    "                                        cnt[y[s_idx]-1][i].append(np.sum(\n",
    "                                            t_ctype[int(i*num_mi): int((i*num_mi) + num_mi)]))\n",
    "                                else:\n",
    "                                    cnt[y[s_idx]-1].append(np.sum(t_ctype))\n",
    "                                    for gr_idx in range(nclasses):\n",
    "                                        '''\n",
    "                                        f_cnt[y[s_idx]-1][gr_idx].append(np.sum(\n",
    "                                            t_ctype[param[\"gr_orth_idx\"][gr_idx+1]]))\n",
    "                                        '''\n",
    "                                        list_cnt[y[s_idx]-1][gr_idx].append(np.sum(\n",
    "                                            t_ctype[param[\"idx_list_all\"][gr_idx]]))\n",
    "                                \n",
    "                            if ctype in ['et']:\n",
    "                                t_ctype = pd.read_csv('count_' + ctype + stat[st] +  \n",
    "                                                      AL[st-1] + str(gidx) + \n",
    "                                                      str(s_idx) + '.csv', header=None)\n",
    "                                t_ctype = np.asarray(t_ctype.values.flatten())\n",
    "                                if st == 0:\n",
    "                                    cnt_train[y[s_idx]-1].append(t_ctype)    \n",
    "                                elif st == 1:\n",
    "                                    cnt_val[y[s_idx]-1].append(t_ctype)\n",
    "                                elif st == 2:\n",
    "                                    cnt_test[y[s_idx]-1].append(t_ctype)\n",
    "                            \n",
    "        if ctype in ['et']:\n",
    "            for st in range(len(stat)):\n",
    "                if st == 0:\n",
    "                    cnt = cnt_train\n",
    "                elif st == 1:\n",
    "                    cnt = cnt_val\n",
    "                elif st == 2:\n",
    "                    cnt = cnt_test\n",
    "                color_list = [\"g\", \"r\", \"b\", \"k\", \"y\", \"c\"]\n",
    "                id_0 = np.flipud(np.argsort(t_ctype[:]))\n",
    "                fig, axes = plt.subplots(1, 3, figsize=(18,6)) # no of classes\n",
    "                for i in range(nclasses):\n",
    "                    for eg in range(np.size(cnt[i], 0)):\n",
    "                        axes[0].plot(np.transpose(np.asarray(cnt[i])[eg, :][id_0]), color_list[i])\n",
    "                axes[0].set_title(\"0. et/ntce2\" + str(st))\n",
    "                axes[0].set_xlabel(\"sensor indices\")\n",
    "                axes[0].set_ylabel(\"sensor responses\")\n",
    "\n",
    "                for i in range(nclasses):\n",
    "                    for eg in range(np.size(cnt[i], 0)):\n",
    "                        axes[1].plot(np.sort(np.asarray(cnt[i])[eg, :][::-1]), color_list[i])\n",
    "\n",
    "                axes[1].set_title(\"1. et/ntce2 sorted\" + str(st))\n",
    "\n",
    "                ref_data = cnt_train[0][0][:]\n",
    "                no_samples = 0\n",
    "                for i in range(nclasses):\n",
    "                    for eg in range(np.size(cnt[i], 0)):\n",
    "                        axes[2].plot(no_samples, distance.euclidean(ref_data, cnt[i][eg][:]),marker='.', \n",
    "                                       linestyle='None', markersize=20, color = color_list[i])\n",
    "                        no_samples =  no_samples + 1\n",
    "                axes[2].set_title(\"2. euc_dist\" + str(st))\n",
    "                axes[2].set_xlabel(\"sample indices\")\n",
    "                axes[2].set_ylabel(\"dist\")\n",
    "\n",
    "                os.chdir(data_add)\n",
    "                fig.savefig(ctype + 'et_resp' + str(st) + '.png')\n",
    "                plt.close(\"all\")\n",
    "\n",
    "                document.add_heading('Unsupervised concentration invariance', level=1)\n",
    "                p = document.add_paragraph()\n",
    "                r = p.add_run()\n",
    "\n",
    "                r.add_picture(ctype + 'et_resp' + str(st) + '.png', width=Inches(6.0), height=Inches(2.))\n",
    "                r.add_text('Figure 0 shows the ET cell responses after application of unsupervised concentration invariance(NTCE2).\\n')\n",
    "                r.add_text('All Train, val, test set combined. X axis: sensor indices, Y axis: sensor responses.\\n')\n",
    "                r.add_text('Fig. 1: same as Fig. 0 but with the sensor responses sorted  - X axis indices are insignificant here.\\n')\n",
    "                r.add_text('Euclidean distances of ET cell responses w.r.t a reference sample - train set sample 0.\\n')\n",
    "                r.add_text('Note: NTCE2 computation is graded.')\n",
    "                os.chdir(add)\n",
    "                            \n",
    "                                    \n",
    "        if ctype in ['apimi', 'mi']:\n",
    "            fig, axes = plt.subplots(1, max(param['mi_dup'], 2), figsize=(18,6))\n",
    "            for j in range(param['mi_dup']):  \n",
    "                color_list = [\"g\", \"r\", \"b\", \"k\", \"y\", \"c\"]\n",
    "                for i in range(nclasses):\n",
    "                    data[i][j] = np.asarray(data[i][j]).flatten()\n",
    "                    bins = np.linspace(-5, 25, 75)\n",
    "                    axes[j].hist(data[i][j], bins, color = color_list[i])\n",
    "                    axes[j].text(16, 350, 'vth:' + format(param[ctype +\"_v_th\"][int(j*num_mi)], '.2f'))\n",
    "                    if ctype == 'apimi':\n",
    "                        axes[j].set_ylim([0, 450])\n",
    "                    elif ctype == 'mi':\n",
    "                        axes[j].set_ylim([0, 1800])\n",
    "                axes[j].set_title(ctype + \"stimes\")\n",
    "                axes[j].set_ylabel(\"#\")\n",
    "                axes[j].set_xlabel(\"spike times\")\n",
    "                \n",
    "            os.chdir(data_add)\n",
    "            fig.savefig(ctype + 'stimes' + '.png')\n",
    "            plt.close(\"all\")\n",
    "        \n",
    "            p = document.add_paragraph()\n",
    "            r = p.add_run()\n",
    "            r.add_picture(ctype + 'stimes' + '.png', width=Inches(6.0), height=Inches(2.))\n",
    "            r.add_text(str(ctype) + '_spiketimes.\\n')\n",
    "            r.add_text('Spike timing distribution of all the input data (6 gas classes).\\n')\n",
    "            r.add_text('Fig. columns correspond to multiple spiking thresholds of mitral cells.\\n')\n",
    "            os.chdir(add)\n",
    "            \n",
    "            fig, axes = plt.subplots(1, max(param['mi_dup'], 2), figsize=(18,6))\n",
    "            for j in range(param['mi_dup']):  \n",
    "                color_list = [\"g\", \"r\", \"b\", \"k\", \"y\", \"c\"]\n",
    "                for n in range(nclasses):\n",
    "                    avg_data[:, n, j] = avg_data[:, n, j]/len(data[n][0])/num_mi\n",
    "                img = axes[j].imshow(avg_data[:, :, j], interpolation='none')\n",
    "            fig.colorbar(img)\n",
    "\n",
    "            os.chdir(data_add)\n",
    "            plt.savefig(ctype + str(j) + 'stimes_map' + '.png')\n",
    "            plt.close(\"all\")\n",
    "\n",
    "            p = document.add_paragraph()\n",
    "            r = p.add_run()\n",
    "            r.add_text(str(ctype) + str(j) + '_avgspiketimes_map.\\n')\n",
    "            r.add_picture(ctype + str(j) + 'stimes_map' + '.png', width=Inches(6.0), height=Inches(2.))\n",
    "            r.add_text('Average spike timings of cells w.r.t diff gas classes.\\n')\n",
    "            r.add_text('Fig. columns correspond to multiple spiking thresholds of mitral cells.\\n')\n",
    "            r.add_text('Y axis: cell indices with a particular threshold, X axis: Gas classes.')\n",
    "            os.chdir(add)\n",
    "               \n",
    "        if ctype in ['gr']:\n",
    "            fig = plt.figure()     \n",
    "            color_list = [\"g\", \"r\", \"b\", \"k\", \"y\", \"c\"]\n",
    "            for i in range(nclasses):\n",
    "                data[i] = np.asarray(data[i]).flatten()\n",
    "                bins = np.linspace(-5, 25, 75)\n",
    "                plt.hist(data[i], bins, color = color_list[i])\n",
    "            plt.title(ctype + \"stimes\")\n",
    "            plt.title(ctype + \"spike time distribution\")\n",
    "            plt.ylabel(\"#\")\n",
    "            plt.xlabel(\"spike times\")\n",
    "            \n",
    "            os.chdir(data_add)\n",
    "            fig.savefig(ctype + 'stimes' + '.png')\n",
    "            plt.close(\"all\")\n",
    "        \n",
    "            p = document.add_paragraph()\n",
    "            r = p.add_run()\n",
    "            r.add_text(str(ctype) + '_spiketimes ')\n",
    "            r.add_picture(ctype + 'stimes' + '.png', width=Inches(6.0), height=Inches(2.))\n",
    "            r.add_text('Granule cell spike timing distributions. ')\n",
    "            os.chdir(add)\n",
    "            \n",
    "        if ctype in ['apimi', 'mi']:\n",
    "            fig, axes = plt.subplots(1, max(param['mi_dup'], 2), figsize=(18,6))\n",
    "            for j in range(param['mi_dup']): \n",
    "                color_list = [\"g\", \"r\", \"b\", \"k\", \"y\", \"c\"]\n",
    "                for i in range(nclasses):\n",
    "                    cnt[i][j] = np.asarray(cnt[i][j]).flatten()\n",
    "                    axes[j].scatter(i* np.ones(len(cnt[i][j])) + 1, \n",
    "                                    np.asarray(cnt[i][j]), color = color_list[i])\n",
    "                    axes[j].set_ylim([0, num_mi])\n",
    "                    axes[j].text(3, 15, 'vth:' + format(param[ctype +\"_v_th\"][int(j*num_mi)], '.2f'))\n",
    "                \n",
    "                axes[j].set_title(ctype + \"_cnt\")\n",
    "                axes[j].set_ylabel(\"#\")\n",
    "                axes[j].set_xlabel(\"spike count\")\n",
    "                \n",
    "            os.chdir(data_add)\n",
    "            fig.savefig(ctype + 'cnt' + '.png')\n",
    "            plt.close(\"all\")\n",
    "            \n",
    "            p = document.add_paragraph()\n",
    "            r = p.add_run()\n",
    "            r.add_picture(ctype + 'cnt' + '.png', width=Inches(6.0), height=Inches(2.))\n",
    "            r.add_text(str(ctype) + '_spikecnt.\\n')\n",
    "            r.add_text('Scatter plots of spike count of all the input data (6 gas classes).\\n')\n",
    "            r.add_text('Fig. columns correspond to multiple spiking thresholds of mitral cells.\\n')\n",
    "            os.chdir(add)\n",
    "                \n",
    "        elif ctype in ['gr']:\n",
    "            fig = plt.figure()     \n",
    "            color_list = [\"g\", \"r\", \"b\", \"k\", \"y\", \"c\"]\n",
    "            for i in range(nclasses):\n",
    "                cnt[i] = np.asarray(cnt[i]).flatten()\n",
    "                plt.scatter(i* np.ones(len(cnt[i])) + 1, np.asarray(cnt[i]), color = color_list[i])\n",
    "            plt.title(\"Gr spike count\")\n",
    "            plt.xlabel(\" Gas classes\")\n",
    "            \n",
    "            os.chdir(data_add)\n",
    "            fig.savefig(ctype + 'cnt' + '.png')\n",
    "            plt.close(\"all\")\n",
    "        \n",
    "            p = document.add_paragraph()\n",
    "            r = p.add_run()\n",
    "            r.add_text(str(ctype) + '_cnt')\n",
    "            r.add_picture(ctype + 'cnt' + '.png', width=Inches(6.0), height=Inches(2.))\n",
    "            r.add_text('Total Granule cell spike count for all the samples - this count includes Gr from all assigned Gr groups to classes.')\n",
    "            os.chdir(add)\n",
    "            \n",
    "        if ctype in ['gr']:\n",
    "            '''\n",
    "            fig, axes = plt.subplots(1, nclasses, figsize=(18,6)) # no of classes\n",
    "            for i in range(nclasses):\n",
    "                for j in range(nclasses):\n",
    "                    f_cnt[i][j] = np.asarray(f_cnt[i][j]).flatten()\n",
    "                    axes[i].scatter(j* np.ones(len(f_cnt[i][j])) + 1, \n",
    "                                    f_cnt[i][j], color = color_list[i])\n",
    "                    axes[j].set_ylim([0, len(param[\"gr_orth_idx\"][1])])\n",
    "                    axes[j].set_xlabel(\" Class indices.\")\n",
    "            plt.title(ctype + \"fcnt\")\n",
    "            \n",
    "            os.chdir(data_add)\n",
    "            fig.savefig(ctype + 'fcnt' + '.png')\n",
    "            plt.close(\"all\")\n",
    "        \n",
    "            p = document.add_paragraph()\n",
    "            r = p.add_run()\n",
    "            r.add_text(str(ctype) + '_fcnt')\n",
    "            r.add_picture(ctype + 'fcnt' + '.png', width=Inches(6.0), height=Inches(2.))\n",
    "            r.add_text('Equal no. of orthogonal Gr cells assigned to each class. From each group some spiked - weights updated for those Gr cell.')\n",
    "            r.add_text('Y axis: Gr spike count, X axis: Class indices')\n",
    "            r.add_text('Each figure depicts the number of Gr that spiked from each assigned groups for a particular gas class.')\n",
    "            os.chdir(add)\n",
    "            '''\n",
    "            \n",
    "            fig, axes = plt.subplots(1, nclasses, figsize=(18,6)) # no of classes\n",
    "            for i in range(nclasses):\n",
    "                for j in range(nclasses):\n",
    "                    list_cnt[i][j] = np.asarray(list_cnt[i][j]).flatten()\n",
    "                    axes[i].scatter(j* np.ones(len(list_cnt[i][j])) + 1, \n",
    "                                    list_cnt[i][j], color = color_list[i])\n",
    "                    axes[j].set_ylim([0, len(param[\"idx_used_all\"])])\n",
    "                    axes[j].set_ylim([0, len(param[\"idx_used_all\"])])\n",
    "                    axes[j].set_xlabel(\" Class indices.\")\n",
    "            plt.title(ctype + \"listcnt\")  \n",
    "            \n",
    "            os.chdir(data_add)\n",
    "            fig.savefig(ctype + 'listcnt' + '.png')\n",
    "            plt.close(\"all\")\n",
    "        \n",
    "            p = document.add_paragraph()\n",
    "            r = p.add_run()\n",
    "            r.add_text(str(ctype) + '_listcnt')\n",
    "            r.add_picture(ctype + 'listcnt' + '.png', width=Inches(6.0), height=Inches(2.))\n",
    "            r.add_text('Same as above but here only Gr that were used for learning were included.')\n",
    "            r.add_text('Equal no. of orthogonal Gr cells assigned to each class. From each group some spiked - weights updated for those Gr cell.')\n",
    "            r.add_text('Y axis: Gr spike count, X axis: Class indices.')\n",
    "            r.add_text('Each figure depicts the number of Gr that spiked from each assigned groups for a particular gas class.')\n",
    "            os.chdir(add)\n",
    "                               \n",
    "    os.chdir(currdir)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spk_times()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HORF():\n",
    "    os.chdir(add)\n",
    "    # import pdb;pdb.set_trace()\n",
    "    syn_wght = pd.read_csv('syn_wght.csv', header=None)\n",
    "    syn_wght = np.asarray(syn_wght.values)\n",
    "    \n",
    "    horf1 = []\n",
    "    horf2 = []\n",
    "    for i in range(np.size(syn_wght, 1)):\n",
    "        idx = np.where(syn_wght[:, i] >= param[\"w_max\"])[0]\n",
    "        horf1.append(len(idx))\n",
    "        idx = np.where(syn_wght[:, i] > 0.)[0]\n",
    "        horf2.append(len(idx))\n",
    "\n",
    "    horf1 = np.asarray(horf1).flatten()\n",
    "    horf2 = np.asarray(horf2).flatten()\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18,6))\n",
    "\n",
    "    axes[0].hist(horf1)\n",
    "    plt.title('Learnt HORF.')\n",
    "    axes[0].set_ylim([0, 600])\n",
    "    \n",
    "    axes[1].hist(horf2)\n",
    "    axes[1].set_ylim([0, 600])\n",
    "    plt.title('HORF.')\n",
    "    \n",
    "    os.chdir(data_add)\n",
    "    fig.savefig('HORF' + '.png')\n",
    "    plt.close(\"all\")\n",
    "\n",
    "    p = document.add_paragraph()\n",
    "    r = p.add_run()\n",
    "    r.add_picture('HORF' + '.png', width=Inches(6.0), height=Inches(2.))\n",
    "    r.add_text('(Left) Distribution of the no. of Mi connected to Gr with max. synaptic strength.')\n",
    "    r.add_text('(Right) Distribution of the no. of Mi connected to Gr with non zero weights.')\n",
    "    os.chdir(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syn_dynamics():\n",
    "    os.chdir(add)\n",
    "    # import pdb;pdb.set_trace()\n",
    "    fig = plt.figure()\n",
    "    for k in range(min(3, len(param['idx_list_all'][0]))):\n",
    "        w = np.load('t_resultsL0.npz')['syn_wght_time'][:, int(param['idx_list_all'][0][int(k)]), :]\n",
    "        # color_w = iter(cm.jet(np.linspace(0, 1, np.size(w, 0))))\n",
    "        for i in range(np.size(w, 0)):\n",
    "        # c = next(color_w)\n",
    "            # plt.plot(w[i, :], color=c)\n",
    "            plt.plot(w[i, :])\n",
    "            plt.ylim([-1., param[\"w_max\"] + 1.])\n",
    "        plt.ylabel('Mi to Gr Weight')\n",
    "    \n",
    "    os.chdir(data_add)\n",
    "    fig.savefig('synw_time' + '.png')\n",
    "    plt.close(\"all\")\n",
    "\n",
    "    p = document.add_paragraph()\n",
    "    r = p.add_run()\n",
    "    r.add_text('synw_time')\n",
    "    r.add_picture('synw_time' + '.png', width=Inches(6.0), height=Inches(2.))\n",
    "    r.add_text('Mi-Gr synaptic weight update profile - in a single gamma cycle.')\n",
    "    os.chdir(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HORF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# syn_dynamics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(classifier_type):\n",
    "    \n",
    "    for gp_idx, grp_typ in enumerate(group_type):\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(18,6))\n",
    "        # idx_list = param[\"idx_list\" + str(gp_idx)]\n",
    "        idx_list = param[\"idx_list_all\"]\n",
    "        \n",
    "        # Gas sensor data set\n",
    "        os.chdir(add)\n",
    "        num_gr = param[\"num_gr\"]\n",
    "        class_gr_bin = []\n",
    "        y_ref  = y_fbL[gp_idx][0:(gp_idx+1)* param[\"nshots\"]][:]\n",
    "        n_trainexamples = len(y_ref)\n",
    "        tmp_act_idx = []\n",
    "        \n",
    "        for i in range(n_trainexamples):\n",
    "            tmp_list = np.zeros(num_gr)\n",
    "            tmp_act_idx.extend(idx_list[i])\n",
    "            tmp_list[idx_list[i]] = 1\n",
    "            class_gr_bin.append(tmp_list[:].tolist())\n",
    "\n",
    "        act_idx = np.unique(np.asarray(tmp_act_idx).flatten()).astype(int)\n",
    "        os.chdir(currdir)\n",
    "\n",
    "        AL_type = ['train_test', 'val_test', 'test_test']\n",
    "        for idx, dtype in enumerate(AL_type):\n",
    "            data_bin = []\n",
    "            y_idT = [[] for _ in range(n_trainexamples)]\n",
    "            y_idF = [[] for _ in range(n_trainexamples)]\n",
    "            dist_T = [[] for _ in range(n_trainexamples)]\n",
    "            y_pred = []\n",
    "            dist_wr = []\n",
    "\n",
    "            if idx == 0:\n",
    "                y = y_fbL[gp_idx]\n",
    "            elif idx == 1:\n",
    "                y = y_val[gp_idx]\n",
    "            elif idx == 2:\n",
    "                y = y_test[gp_idx]\n",
    "            os.chdir(add)\n",
    "            for sample_idx in range(len(y)):\n",
    "                count_gr = pd.read_csv('count_gr' + 'AL' + AL_type[idx] + \n",
    "                                       str(gp_idx) + str(sample_idx) + '.csv', header=None)\n",
    "                count_gr_bin = np.asarray(count_gr.values.flatten())\n",
    "                data_bin.append(count_gr_bin)\n",
    "                os.chdir(add)\n",
    "\n",
    "            ovlp = np.zeros((n_trainexamples, np.size(data_bin, 0)))\n",
    "            for test_idx in range(np.size(data_bin, 0)):\n",
    "                for i in range(n_trainexamples):\n",
    "                    '''\n",
    "                    ovlp[i, test_idx] = distance.hamming(\n",
    "                        np.asarray(class_gr_bin[i])[param[\"gr_orth_idx\"][y_fbL[gp_idx][i]]],\n",
    "                        np.asarray(data_bin[test_idx])[param[\"gr_orth_idx\"][y_fbL[gp_idx][i]]])\n",
    "                    '''\n",
    "                    if classifier_type == 'hamming':\n",
    "                        '''\n",
    "                        x1 = np.asarray(class_gr_bin[i])[param[\"idx_list_all\"][y_ref[i]-1]]\n",
    "                        x2 = np.asarray(data_bin[test_idx])[param[\"idx_list_all\"][y_ref[i]-1]]\n",
    "                        '''\n",
    "                        '''\n",
    "                        x1 = np.asarray(class_gr_bin[i])[param[\"idx_list_all\"][i]]\n",
    "                        x2 = np.asarray(data_bin[test_idx])[param[\"idx_list_all\"][i]]\n",
    "                        '''\n",
    "                        x1 = np.asarray(class_gr_bin[i])\n",
    "                        x2 = np.asarray(data_bin[test_idx])\n",
    "                        ovlp[i, test_idx] = distance.hamming(x1, x2)\n",
    "                    elif classifier_type == 'ovlp':\n",
    "                        '''\n",
    "                        x1 = np.asarray(class_gr_bin[i])[param[\"idx_list_all\"][y_ref[i]-1]]\n",
    "                        x2 = np.asarray(data_bin[test_idx])[param[\"idx_list_all\"][y_ref[i]-1]]\n",
    "                        '''\n",
    "                        '''\n",
    "                        x1 = np.asarray(class_gr_bin[i])[param[\"idx_list_all\"][i]]\n",
    "                        x2 = np.asarray(data_bin[test_idx])[param[\"idx_list_all\"][i]]   \n",
    "                        '''\n",
    "                        x1 = np.asarray(class_gr_bin[i])\n",
    "                        x2 = np.asarray(data_bin[test_idx])\n",
    "                        if np.linalg.norm(x1) * np.linalg.norm(x2):\n",
    "                            ovlp[i, test_idx] = (np.dot(x1, x2)/(np.linalg.norm(x1) * np.linalg.norm(x2)))\n",
    "            \n",
    "                if classifier_type == 'hamming':\n",
    "                    if ovlp[np.argmin(ovlp[:, test_idx]), test_idx] > 0.5:\n",
    "                        y_pred.append(0)\n",
    "                    else:\n",
    "                        y_pred.append(y_ref[np.argmin(ovlp[:, test_idx])])\n",
    "                        \n",
    "                        for target_idx, target_val in enumerate(y_ref):\n",
    "                            if y_ref[np.argmin(ovlp[:, test_idx])] == target_val:\n",
    "                                if y[test_idx] == target_val:\n",
    "                                    y_idT[target_idx].append(test_idx)\n",
    "                                    dist_T[target_idx].append(ovlp[np.argmin(ovlp[:, test_idx]), test_idx])\n",
    "                                    all_rem_idx = np.setdiff1d(np.arange(len(y_ref)), \n",
    "                                                               np.argmin(ovlp[:, test_idx]))\n",
    "                                    for index in all_rem_idx:\n",
    "                                        dist_wr.append(ovlp[index, test_idx])\n",
    "                                else:\n",
    "                                    y_idF[target_idx].append(test_idx)\n",
    "                        \n",
    "                elif classifier_type == 'ovlp':\n",
    "                    if ovlp[np.argmax(ovlp[:, test_idx]), test_idx] < 0.5:\n",
    "                        y_pred.append(0)\n",
    "                    else:\n",
    "                        y_pred.append(y_ref[np.argmax(ovlp[:, test_idx])])\n",
    "                       \n",
    "                        for target_idx, target_val in enumerate(y_ref):\n",
    "                            if y_ref[np.argmax(ovlp[:, test_idx])] == target_val:\n",
    "                                if y[test_idx] == target_val:\n",
    "                                    y_idT[target_idx].append(test_idx)\n",
    "                                    dist_T[target_idx].append(ovlp[np.argmax(ovlp[:, test_idx]), test_idx])\n",
    "                                    all_rem_idx = np.setdiff1d(np.arange(len(y_ref)), \n",
    "                                                               np.argmax(ovlp[:, test_idx]))\n",
    "                                    for index in all_rem_idx:\n",
    "                                        dist_wr.append(ovlp[index, test_idx])\n",
    "                                else:\n",
    "                                    y_idF[target_idx].append(test_idx) \n",
    "                     \n",
    "           \n",
    "            df = pd.DataFrame(y_pred)\n",
    "            df.to_csv(\"pred\" + classifier_type + str(idx) + \"_\" + str(gp_idx) + \".csv\")\n",
    "            os.chdir(data_add)\n",
    "            df.to_csv(\"pred\" + classifier_type + str(idx) + \"_\" + str(gp_idx) + \".csv\")\n",
    "            os.chdir(currdir)\n",
    "            \n",
    "            if classifier_type == 'ovlp' and gp_idx == (nclasses - 1):\n",
    "                color_list = [\"g\", \"r\", \"b\", \"k\", \"y\", \"c\"]\n",
    "                fig0, axes0 = plt.subplots(1, nclasses, figsize=(18,6))\n",
    "                for i in range(np.size(ovlp, 1)):\n",
    "                    for k in range(nclasses):\n",
    "                        axes0[y[i]-1].plot(k, ovlp[k, i], marker='.', \n",
    "                                          linestyle='None', markersize=20, color = color_list[y[i]-1]) \n",
    "            \n",
    "                os.chdir(data_add)\n",
    "                fig0.savefig(dtype + classifier_type + '.png')\n",
    "                plt.close(\"all\")\n",
    "                \n",
    "                document.add_heading(dtype + '_overlap', level=1)\n",
    "                p = document.add_paragraph()\n",
    "                r = p.add_run()\n",
    "                r.add_text(dtype + classifier_type)\n",
    "                r.add_picture(dtype + classifier_type + '.png', width=Inches(6.0), height=Inches(2.))\n",
    "                r.add_text(dtype + str(':') + 'X axis: Gas class indices, Y axis: value of overlap (normalized dot product).')\n",
    "                r.add_text('Each figure describe the overlap value of Gr responses for a particular class of sensor input')\n",
    "                os.chdir(add)\n",
    "        '''  \n",
    "        color_list = [\"g\", \"r\", \"b\", \"k\", \"y\", \"c\"]\n",
    "        for i in range(n_trainexamples):\n",
    "            axes[0].hist(np.asarray(dist_T[i]), color = color_list[i])\n",
    "            axes[1].hist(np.asarray(dist_wr), color=\"m\")\n",
    "        axes[0].set_xlim([0., 1.])\n",
    "        axes[0].set_ylim([0., 100.])\n",
    "        axes[1].set_xlim([0., 1.])\n",
    "        axes[1].set_ylim([0., 500.])\n",
    "        # import pdb;pdb.set_trace()\n",
    "        os.chdir(data_add)\n",
    "        fig.savefig(grp_typ + classifier_type + 'hist' + '.png')\n",
    "        plt.close(\"all\")\n",
    "\n",
    "        p = document.add_paragraph()\n",
    "        r = p.add_run()\n",
    "        r.add_text(grp_typ + dtype + classifier_type + 'hist')\n",
    "        r.add_picture(grp_typ + classifier_type + 'hist' + '.png', width=Inches(6.0), height=Inches(2.))\n",
    "        r.add_text('Group 1: Train class1, test on all, Group 2: Train on 1 & 2, test on all ...')\n",
    "        r.add_text('(Left) Correct classification:' + classifier_type)\n",
    "        r.add_text('(Right) Remaining incorrect values:' + classifier_type)\n",
    "        os.chdir(add)\n",
    "        '''\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_accuracy(classifier_type):\n",
    "    \n",
    "        test_type = ['fbL', 'val', 'test']\n",
    "        for idx in range(len(test_type)):\n",
    "            \n",
    "            if test_type[idx] == 'test':\n",
    "                comp_res = []\n",
    "            \n",
    "            document.add_heading('Results_' + classifier_type + '_' + test_type[idx], level=2)\n",
    "            table = document.add_table(rows=10, cols=7)\n",
    "            table.style = 'TableGrid'\n",
    "\n",
    "            for i in range(nclasses):\n",
    "                row = table.rows[i+1]\n",
    "                row.cells[0].text = \"class_\" + str(i+1)\n",
    "            row = table.rows[7]\n",
    "            row.cells[0].text = 'None'\n",
    "            row = table.rows[8]\n",
    "            row.cells[0].text = 'Avg.'\n",
    "            row = table.rows[9]\n",
    "            row.cells[0].text = 'class Avg.'\n",
    "            row = table.rows[0]\n",
    "                \n",
    "            for gp_idx, grp_typ in enumerate(group_type):\n",
    "                # idx_list = param[\"idx_list\" + str(gp_idx)]\n",
    "                row.cells[gp_idx + 1].text = grp_typ\n",
    "\n",
    "                os.chdir(add)\n",
    "                if idx == 0:\n",
    "                    df = y_fbL[gp_idx]\n",
    "                elif idx == 1:\n",
    "                    df = y_val[gp_idx]\n",
    "                elif idx == 2:\n",
    "                    df = y_test[gp_idx]\n",
    "\n",
    "                for val in range(len(df)):\n",
    "                    if df[val] > (gp_idx + 1):\n",
    "                        df[val] = 0\n",
    "                df_pred = pd.read_csv('pred' + classifier_type + str(idx) + \"_\" + \n",
    "                                      str(gp_idx) + '.csv', header=None)\n",
    "                df_pred = df_pred[1][1:]\n",
    "                os.chdir(currdir)\n",
    "\n",
    "                pred = np.zeros(7)\n",
    "                count = np.zeros(7)\n",
    "                val = np.zeros(6)\n",
    "                none_above  = 0\n",
    "                none_all = 0\n",
    "\n",
    "                for i in range(len(df)):\n",
    "                    if df[i] == 0:\n",
    "                        none_all = none_all + 1\n",
    "                    else:\n",
    "                        count[-1] = count[-1] + 1\n",
    "                        count[df[i]-1] = count[df[i]-1] + 1\n",
    "\n",
    "                    if df[i] == df_pred[i + 1]:\n",
    "                        pred[-1] = pred[-1] + 1\n",
    "                        if df[i] > 0:\n",
    "                            pred[df[i]-1] = pred[df[i]-1] + 1\n",
    "                        elif df[i] == 0:\n",
    "                            none_above = none_above + 1\n",
    "                    else:\n",
    "                        if df[i] > 0:\n",
    "                            val[df[i]-1] = val[df[i]-1] + 1\n",
    "                \n",
    "                print(test_type[idx], grp_typ)\n",
    "                # import pdb;pdb.set_trace()\n",
    "                for i in range(nclasses):\n",
    "                    rowc = table.rows[i+1]\n",
    "                    rowc.cells[gp_idx + 1].text = format((pred[i]/max(count[i], 1)) * 100, '.2f')\n",
    "                    print((pred[i]/max(count[i], 1)) * 100)\n",
    "                for i in range(nclasses):\n",
    "                    print((val[i]/max(count[i], 1)) * 100)\n",
    "                rowc = table.rows[7]\n",
    "                rowc.cells[gp_idx + 1].text = format(((none_above/max(1, none_all)) * 100), '.2f')\n",
    "                rowc = table.rows[8]\n",
    "                rowc.cells[gp_idx + 1].text = format(((pred[-1]/(count[-1]+none_all)) * 100), '.2f')\n",
    "                rowc = table.rows[9]\n",
    "                class_pred = 0\n",
    "                for gx in range(gp_idx+1):\n",
    "                    class_pred = class_pred + pred[gx]\n",
    "                rowc.cells[gp_idx + 1].text = format(((class_pred/(count[-1])) * 100), '.2f')\n",
    "                if test_type[idx] == 'test':\n",
    "                    # comp_res.append((class_pred/(count[-1])) * 100)\n",
    "                    comp_res.append(format(((class_pred/(count[-1])) * 100), '.2f'))\n",
    "                print(pred[-1], count[-1], none_above)\n",
    "                print((pred[-1]/(count[-1]+none_all)) * 100)\n",
    "                print((none_above/max(1, none_all)) * 100)\n",
    "            if test_type[idx] == 'test':\n",
    "                df = pd.DataFrame(comp_res)\n",
    "                os.chdir(all_results)\n",
    "                df.to_csv(\"comp_res\" + \"_\" + str(batch_idx) + \"_\" + str(nshots) + \"_\" + str(ins) + \"_\" + str(classifier_type) + \".csv\")\n",
    "                os.chdir(currdir)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/borthakur/anaconda3/envs/pytorch/lib/python3.7/site-packages/docx/styles/styles.py:143: UserWarning: style lookup by style_id is deprecated. Use style name as key instead.\n",
      "  return self._get_style_id_from_style(self[style_name], style_type)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fbL group1\n",
      "100.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0 1.0 0\n",
      "16.666666666666664\n",
      "0.0\n",
      "fbL group2\n",
      "100.0\n",
      "100.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.0 2.0 0\n",
      "33.33333333333333\n",
      "0.0\n",
      "fbL group3\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "3.0 3.0 0\n",
      "50.0\n",
      "0.0\n",
      "fbL group4\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "4.0 4.0 0\n",
      "66.66666666666666\n",
      "0.0\n",
      "fbL group5\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "5.0 5.0 0\n",
      "83.33333333333334\n",
      "0.0\n",
      "fbL group6\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "6.0 6.0 0\n",
      "100.0\n",
      "0.0\n",
      "val group1\n",
      "100.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "7.0 7.0 0\n",
      "15.555555555555555\n",
      "0.0\n",
      "val group2\n",
      "100.0\n",
      "100.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "16.0 16.0 0\n",
      "35.55555555555556\n",
      "0.0\n",
      "val group3\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "23.0 23.0 0\n",
      "51.11111111111111\n",
      "0.0\n",
      "val group4\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "26.0 26.0 0\n",
      "57.77777777777777\n",
      "0.0\n",
      "val group5\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "77.77777777777779\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "22.22222222222222\n",
      "0.0\n",
      "33.0 35.0 0\n",
      "73.33333333333333\n",
      "0.0\n",
      "val group6\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "77.77777777777779\n",
      "100.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "22.22222222222222\n",
      "0.0\n",
      "43.0 45.0 0\n",
      "95.55555555555556\n",
      "0.0\n",
      "test group1\n",
      "100.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "82.0 82.0 0\n",
      "20.812182741116754\n",
      "0.0\n",
      "test group2\n",
      "100.0\n",
      "98.86363636363636\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.1363636363636365\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "169.0 170.0 0\n",
      "42.89340101522843\n",
      "0.0\n",
      "test group3\n",
      "100.0\n",
      "98.86363636363636\n",
      "94.66666666666667\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.1363636363636365\n",
      "5.333333333333334\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "240.0 245.0 0\n",
      "60.913705583756354\n",
      "0.0\n",
      "test group4\n",
      "100.0\n",
      "98.86363636363636\n",
      "94.66666666666667\n",
      "100.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.1363636363636365\n",
      "5.333333333333334\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "266.0 271.0 0\n",
      "67.51269035532995\n",
      "0.0\n",
      "test group5\n",
      "100.0\n",
      "98.86363636363636\n",
      "94.66666666666667\n",
      "100.0\n",
      "81.66666666666667\n",
      "0.0\n",
      "0.0\n",
      "1.1363636363636365\n",
      "5.333333333333334\n",
      "0.0\n",
      "18.333333333333332\n",
      "0.0\n",
      "315.0 331.0 0\n",
      "79.94923857868021\n",
      "0.0\n",
      "test group6\n",
      "100.0\n",
      "98.86363636363636\n",
      "94.66666666666667\n",
      "100.0\n",
      "81.66666666666667\n",
      "98.4126984126984\n",
      "0.0\n",
      "1.1363636363636365\n",
      "5.333333333333334\n",
      "0.0\n",
      "18.333333333333332\n",
      "1.5873015873015872\n",
      "377.0 394.0 0\n",
      "95.68527918781726\n",
      "0.0\n",
      "fbL group1\n",
      "100.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0 1.0 0\n",
      "16.666666666666664\n",
      "0.0\n",
      "fbL group2\n",
      "100.0\n",
      "100.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.0 2.0 0\n",
      "33.33333333333333\n",
      "0.0\n",
      "fbL group3\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "3.0 3.0 0\n",
      "50.0\n",
      "0.0\n",
      "fbL group4\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "4.0 4.0 0\n",
      "66.66666666666666\n",
      "0.0\n",
      "fbL group5\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "5.0 5.0 0\n",
      "83.33333333333334\n",
      "0.0\n",
      "fbL group6\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "6.0 6.0 0\n",
      "100.0\n",
      "0.0\n",
      "val group1\n",
      "100.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "7.0 7.0 0\n",
      "15.555555555555555\n",
      "0.0\n",
      "val group2\n",
      "100.0\n",
      "100.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "16.0 16.0 0\n",
      "35.55555555555556\n",
      "0.0\n",
      "val group3\n",
      "100.0\n",
      "100.0\n",
      "85.71428571428571\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "14.285714285714285\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "22.0 23.0 0\n",
      "48.888888888888886\n",
      "0.0\n",
      "val group4\n",
      "100.0\n",
      "100.0\n",
      "85.71428571428571\n",
      "100.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "14.285714285714285\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "25.0 26.0 0\n",
      "55.55555555555556\n",
      "0.0\n",
      "val group5\n",
      "100.0\n",
      "100.0\n",
      "85.71428571428571\n",
      "100.0\n",
      "77.77777777777779\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "14.285714285714285\n",
      "0.0\n",
      "22.22222222222222\n",
      "0.0\n",
      "32.0 35.0 0\n",
      "71.11111111111111\n",
      "0.0\n",
      "val group6\n",
      "100.0\n",
      "100.0\n",
      "85.71428571428571\n",
      "100.0\n",
      "77.77777777777779\n",
      "90.0\n",
      "0.0\n",
      "0.0\n",
      "14.285714285714285\n",
      "0.0\n",
      "22.22222222222222\n",
      "10.0\n",
      "41.0 45.0 0\n",
      "91.11111111111111\n",
      "0.0\n",
      "test group1\n",
      "100.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "82.0 82.0 0\n",
      "20.812182741116754\n",
      "0.0\n",
      "test group2\n",
      "100.0\n",
      "98.86363636363636\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.1363636363636365\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "169.0 170.0 0\n",
      "42.89340101522843\n",
      "0.0\n",
      "test group3\n",
      "100.0\n",
      "98.86363636363636\n",
      "94.66666666666667\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.1363636363636365\n",
      "5.333333333333334\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "240.0 245.0 0\n",
      "60.913705583756354\n",
      "0.0\n",
      "test group4\n",
      "100.0\n",
      "98.86363636363636\n",
      "94.66666666666667\n",
      "100.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.1363636363636365\n",
      "5.333333333333334\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "266.0 271.0 0\n",
      "67.51269035532995\n",
      "0.0\n",
      "test group5\n",
      "100.0\n",
      "98.86363636363636\n",
      "94.66666666666667\n",
      "100.0\n",
      "80.0\n",
      "0.0\n",
      "0.0\n",
      "1.1363636363636365\n",
      "5.333333333333334\n",
      "0.0\n",
      "20.0\n",
      "0.0\n",
      "314.0 331.0 0\n",
      "79.69543147208121\n",
      "0.0\n",
      "test group6\n",
      "100.0\n",
      "98.86363636363636\n",
      "94.66666666666667\n",
      "100.0\n",
      "80.0\n",
      "98.4126984126984\n",
      "0.0\n",
      "1.1363636363636365\n",
      "5.333333333333334\n",
      "0.0\n",
      "20.0\n",
      "1.5873015873015872\n",
      "376.0 394.0 0\n",
      "95.43147208121827\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_idx = 1\n",
    "ins=1\n",
    "# shots = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "shots = [1]\n",
    "for nshots in shots:\n",
    "    currdir = os.getcwd()\n",
    "\n",
    "    group_type = ['group1', 'group2', 'group3', 'group4', 'group5', 'group6']\n",
    "    # stat = ['B4L', 'L', 'AL']\n",
    "    stat = ['L', 'AL', 'AL']\n",
    "    data_stat = ['train', 'val', 'test']\n",
    "    AL = ['val_test', 'test_test']\n",
    "    nclasses = 6\n",
    "    path = os.path.normpath(os.getcwd() + os.sep + os.pardir)\n",
    "    path = os.path.normpath(path + os.sep + os.pardir)\n",
    "    path = os.path.normpath(path + os.sep + os.pardir)\n",
    "    all_results = os.path.join(path, 'NICE_results/drift/1')\n",
    "    path = os.path.join(path, 'NICE_results/drift/1')\n",
    "    \n",
    "    os.chdir(path)\n",
    "    idx_add = sorted(os.listdir())\n",
    "    idx = [fname for fname in idx_add if fname.endswith('_run_parallel')][-3]\n",
    "    data_idx = [fname for fname in idx_add if fname.endswith('__sim_info')][-3]\n",
    "    \n",
    "    os.chdir(currdir)\n",
    "    add = \"/\".join([path, idx])\n",
    "    data_add = \"/\".join([path, data_idx])\n",
    "    os.chdir(add)\n",
    "    with open('param.p', \"rb\") as handle:\n",
    "        param = pickle.load(handle)\n",
    "    os.chdir(currdir)\n",
    "    data_path = os.path.normpath(os.getcwd() + os.sep + os.pardir)\n",
    "    data_path = os.path.normpath(data_path + os.sep + os.pardir)\n",
    "    data_path = os.path.normpath(data_path + os.sep + os.pardir)\n",
    "    data_path = os.path.join(data_path, 'data')\n",
    "    data_path = os.path.join(data_path, 'fneuro_data/' + str(nshots) + \n",
    "                             'shot/batch' + str(batch_idx) + '/set1') # input data location\n",
    "\n",
    "    os.chdir(data_add)\n",
    "    # document.add_heading('Ordinal forcing', level=1)\n",
    "    document.add_heading('NTCE2', level=1)\n",
    "    document.add_heading('Drift data - Batch1', level=1)\n",
    "    document.add_heading('Important parameters', level=1)\n",
    "    document.add_heading('ET+PG cells', level=2)\n",
    "    p = document.add_paragraph()\n",
    "    r = p.add_run()\n",
    "    r.add_text(\"num_et=\" + str(param[\"num_et\"],) + '\\t')\n",
    "    r.add_text(\"num_et=\" + str(param[\"num_pg\"],) + '\\t')\n",
    "    document.add_heading('Apical Mitral cells', level=2)\n",
    "    p = document.add_paragraph()\n",
    "    r = p.add_run()\n",
    "    r.add_text(\"num_apimi=\" + str(param[\"num_apimi\"],) + '\\t')\n",
    "    r.add_text(\"v_th_apimi=\" + str(param[\"v_th_apimi\"]) + '\\t')\n",
    "    document.add_heading('Mitral cells', level=2)\n",
    "    p = document.add_paragraph()\n",
    "    r = p.add_run()\n",
    "    r.add_text(\"num_mi=\" + str(param[\"num_mi\"],) + '\\t')\n",
    "    r.add_text(\"mi_dup=\" + str(param[\"mi_dup\"],) + '\\t')\n",
    "    r.add_text(\"v_th_mi_min=\" + str(param[\"v_th_mi_min\"], ) + '\\t')\n",
    "    r.add_text(\"v_th_mi_max=\" + str(param[\"v_th_mi_max\"]) + '\\t')\n",
    "    r.add_text(\"v_th_gr_min=\" + str(param[\"v_th_gr_min\"], ) + '\\t')\n",
    "    r.add_text(\"v_th_gr_max=\" + str(param[\"v_th_gr_max\"]) + '\\t')\n",
    "    r.add_text(\"a_p_mg=\" + str(param[\"a_p_mg\"]) + '\\t')\n",
    "    r.add_text(\"tau_p_mg=\" + str(param[\"tau_p_mg\"]) + '\\t')\n",
    "    document.add_heading('Granule cells', level=2)\n",
    "    p = document.add_paragraph()\n",
    "    r = p.add_run()\n",
    "    r.add_text(\"v_th_gr=\" + str(param[\"v_th_gr\"]) + '\\t')\n",
    "    # r.add_text(\"No of Gr assigned /class=\" + str(len(param[\"gr_orth_idx\"][1])) + '\\t')\n",
    "    r.add_text(\"num_gr=\" + str(param[\"num_gr\"]) + '\\t')\n",
    "    document.add_heading('Network', level=2)\n",
    "    p = document.add_paragraph()\n",
    "    r = p.add_run()\n",
    "    r.add_text(\"Mi-Gr connection probability=\" + str(param[\"cp\"]) + '\\t')\n",
    "    r.add_text(\"Peak conductance change(gmax)=\" + str(param[\"gmax_exc\"]) + '\\t')\n",
    "    r.add_text(\"Initial synaptic weight=\" + str(param[\"syn_wght\"]) + '\\t')\n",
    "    # r.add_text(\"Max. allowed synaptic weight=\" + str(param[\"w_max\"]) + '\\t')\n",
    "    r.add_text(\"Oscillation frequency=\" + str(param[\"f\"]) + '\\t')\n",
    "    r.add_text(\"Oscillation offset parameter=\" + str(param[\"offset_osc\"]) + '\\t')\n",
    "    r.add_text(\"Oscillation sinusoid scaling parameter=\" + str(param[\"amp_osc\"]) + '\\t')\n",
    "    r.add_text(\"Nernst potential=\" + str(param[\"en_exc\"]) + '\\t')\n",
    "    r.add_text(\"Integration time step (dt)=\" + str(param[\"dt\"]) + '\\t')\n",
    "    os.chdir(add)\n",
    "\n",
    "    y_train = [[] for _ in range(len(group_type))]\n",
    "    y_fbL = [[] for _ in range(len(group_type))]\n",
    "    y_val = [[] for _ in range(len(group_type))]\n",
    "    y_test = [[] for _ in range(len(group_type))]\n",
    "    idx_list = [[] for _ in range(len(group_type))]\n",
    "    plot_typ = ['fbL', 'val', 'test']\n",
    "    for idx, grp_typ in enumerate(group_type):\n",
    "        # idx_list[idx] = param[\"idx_list_all\" + str(idx)]\n",
    "        idx_list[idx] = param[\"idx_list_all\"]\n",
    "        grp_path = os.path.join(data_path, grp_typ)\n",
    "        os.chdir(grp_path)\n",
    "        y_train[idx] = pd.read_csv('y_train.csv', header=None)\n",
    "        y_train[idx] = y_train[idx][0]\n",
    "        y_fbL[idx] = pd.read_csv('y_fbL.csv', header=None)\n",
    "        y_fbL[idx] = y_fbL[idx][0]\n",
    "        y_val[idx] = pd.read_csv('y_val.csv', header=None)\n",
    "        y_val[idx] = y_val[idx][0]\n",
    "        y_test[idx] = pd.read_csv('y_test.csv', header=None)\n",
    "        y_test[idx] = y_test[idx][0]\n",
    "        if idx == len(group_type)-1:\n",
    "            document.add_heading('Input data', level=1)\n",
    "            color_list = [\"g\", \"r\", \"b\", \"k\", \"y\", \"c\"]   \n",
    "            fig, axes = plt.subplots(3, len(plot_typ), figsize=(18,6)) # no of classes\n",
    "            for pidx, ptyp in enumerate(plot_typ):\n",
    "                if pidx == 0:\n",
    "                    y = y_fbL[idx]\n",
    "                elif pidx == 1:\n",
    "                    y = y_val[idx]\n",
    "                elif pidx == 2:\n",
    "                    y = y_test[idx]\n",
    "                data = pd.read_csv(ptyp + '_data.csv', header=None)\n",
    "                data = np.asarray(data.values)\n",
    "                scaled_data = pd.read_csv(ptyp + '_data_scaled.csv', header=None)\n",
    "                scaled_data = np.asarray(scaled_data.values)\n",
    "                id_0 = np.flipud(np.argsort(data[0, :]))\n",
    "                # print(pidx, np.shape(data), len(y))\n",
    "                for i in range(len(y)):\n",
    "                    if pidx == 0 and i == 0:\n",
    "                        ref_data = data[i, :]\n",
    "                        ref_sc_data = scaled_data[i, :]\n",
    "                    axes[0, pidx].plot(np.transpose(data[i, :][id_0]), color = color_list[y[i]-1])\n",
    "                    axes[1, pidx].plot(i, distance.euclidean(ref_data, data[i, :]),marker='.', \n",
    "                                       linestyle='None', markersize=20, color = color_list[y[i]-1])\n",
    "                    axes[2, pidx].plot(i, distance.euclidean(ref_sc_data, scaled_data[i, :]),marker='.', \n",
    "                                       linestyle='None', markersize=20, color = color_list[y[i]-1])\n",
    "\n",
    "                # axes[0, pidx].text(12, 350000, ptyp)\n",
    "                axes[0, pidx].text(14, 600000, str(pidx))\n",
    "                axes[1, pidx].text(2, 0.9, \"raw\")\n",
    "                axes[2, pidx].text(2, 0.9, \"scaled\")\n",
    "            os.chdir(data_add)\n",
    "            fig.savefig('original_data' + '.png')\n",
    "            plt.close(\"all\")\n",
    "\n",
    "            r = p.add_run()\n",
    "            r.add_picture('original_data' + '.png', width=Inches(6.0), height=Inches(2.))\n",
    "            r.add_text('Row 1(0,1,2): Raw sensor responses of train set, val set and test set.6 gas classes, 1 sample/class for train set.\\n')\n",
    "            r.add_text('Row 2 (0,1,2): Euclidean distances of raw sensor response samples w.r.t a reference sample  - sample 0 of train set.\\n')\n",
    "            r.add_text('Row 3(0, 1,2): Same as above but after sensor scaling - sensor scaling figures below.\\n')\n",
    "            os.chdir(grp_path)\n",
    "\n",
    "            # document.add_heading('Input data', level=1)\n",
    "            p = document.add_paragraph()\n",
    "            plot_typ = ['fbL', 'val', 'test']\n",
    "            for ptyp in plot_typ:\n",
    "                r = p.add_run()\n",
    "                r.add_picture('scaled_' + ptyp +'_dataprofile.png', width=Inches(6.0), height=Inches(2.))\n",
    "                r.add_text(ptyp) \n",
    "                r.add_text('\\nY axis: Sensor responses after sensor scaling, X axis: Sensor indices.')\n",
    "                if ptyp == 'fbL':\n",
    "                    p.add_run('Train set (after sensor scaling), 6 gas classes, 1 sample/class.')\n",
    "                    p.add_run('Also used to generate sensor scaling parameters.')\n",
    "                elif ptyp == 'val':\n",
    "                     p.add_run('Validation set (after sensor scaling), Randomly selected 10 % of batch 1 data. ')\n",
    "                elif ptyp == 'test':\n",
    "                     p.add_run('Test set (after sensor scaling).')\n",
    "\n",
    "        os.chdir(currdir)\n",
    "\n",
    "    classifier_type = ['hamming', 'dot', 'ovlp', 'complexdot']\n",
    "    predictions(classifier_type[0])\n",
    "    comp_accuracy(classifier_type[0])\n",
    "    predictions(classifier_type[2])\n",
    "    comp_accuracy(classifier_type[2])\n",
    "    os.chdir(data_add)\n",
    "    document.save(str(data_idx) + 'results.docx')\n",
    "    os.chdir(currdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
